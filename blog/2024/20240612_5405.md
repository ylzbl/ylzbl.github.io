# 马斯克跟苹果互怼，但他们没告诉你的AI隐私真相是？

*James|2024-06-12|AIGC*

作者|James

北京时间周二凌晨，苹果公司发布了关于AI的最新更新，并给其AI功能取了一个双关的称呼：“果工智能”（Apple Intelligence）。在这次发布会上虽然没有太多惊艳之处，但“隐私”这个概念被反复强调了十几次。

即使如此，也有一位“资深网友”对此不以为然，这就是埃隆·马斯克。

在苹果发布会之后，马斯克痛批苹果与OpenAI之间的合作，认为这无异于将用户的隐私信息毫无保留地转手给OpenAI，并配了一张梗图，称苹果作为用户隐私被出卖给OpenAI的中间商。

![Image](http://static.ylzbl.com/uploads/ueditor/php/upload/image/20240612/1718165131982301.jpeg)

他甚至提到，如果苹果对ChatGPT是系统级别的集成，他将不允许员工将iPhone带入特斯拉，如果访客带着iPhone进来，也需要把手机锁在前台的“法拉第笼”里面。

![Image](http://static.ylzbl.com/uploads/ueditor/php/upload/image/20240612/1718165132310998.jpeg)

马斯克本人（而不是高仿号）发表此言论后，大部分科技媒体都持不以为然的态度，指出他对于苹果实现设备AI的方式缺乏足够的理解。

根据苹果的官方演示，在Siri等地调动ChatGPT的方式，是首先会询问用户是否引用ChatGPT，在此之后代为做一次性的简单查询。这其中，ChatGPT就像网络搜索一样，只不过Siri之前调用搜索引擎，会带来一大串杂乱的搜索结果，现在改为直接用GPT输出一个段落的答案，感觉更好。

![Image](http://static.ylzbl.com/uploads/ueditor/php/upload/image/20240612/1718165132370902.jpeg)

如果仅限于此，网传Siri在中国的AI能力会被替换成百度的文心一言，那效果其实也不会差太多，因为这种自然语言替代主要是集中于搜索功能。其实，百度的AI搜索结果精选，效果比谷歌英文版的还好一些——后者因为奇葩结果太多，不得不临时降低了在结果页面的展示频率。

苹果推出的其他AI功能，依靠手机本身的芯片运算，或转给苹果自己的网络端的大模型，这些运算并不依赖ChatGPT或其它第三方大模型。苹果还指出，临时需要上传的数据会经过一个与目前iCloud等单独分开的服务器，并隐藏相关可识别的用户信息，甚至苹果内部员工也无法访问。

我们普通消费者也没法证实苹果的单方面陈述，但毋庸置疑的是，“隐私”现在确实是苹果设备相对于Android等其他阵营的一个巨大卖点。特别是在后乔布斯时代，苹果逐渐陷入创新乏力、“挤牙膏、割韭菜”的质疑声音中。为了普通用户难以感知的升级，每年多花几千块钱换新设备，这种必要性确实越来越受到质疑。所以，无论是否年年换新，一部分苹果用户宁愿舍弃微信双开、通话录音等便利，可能正是为了那份对隐私极度重视，带来的安全和清静的感觉。

![Image](http://static.ylzbl.com/uploads/ueditor/php/upload/image/20240612/1718165133223113.jpeg)

马斯克所说的质疑，更多其实是针对OpenAI一方表达不满。马斯克退出OpenAI管理层，之后又对其提起诉讼，其核心诉求在于让OpenAI回到创业之初的非营利承诺，而不是只顾着赚钱。这一点比较抽象，但对马斯克来说则是很重要的问题。与他持有类似观念的还有OpenAI的“超级对齐”团队，他们希望充分监管人工智能的发展，确保它不会失控。但该团队在去年底的一次“宫斗”中失败而解散。

这些争论对于普通人是很难理解的。大家更关心的是，马斯克的质疑是不是真实的？即使不是苹果，其它AI大模型是否也很容易泄露用户隐私？这一点迫切需要一个明确的答案。

简单的回答就是，AI产品有可能发生隐私泄露，但截至目前，隐私泄露的成因是与AI无关的，更多是传统的安全威胁。

我们使用AI出于个人或工作目的，所以害怕泄露个人隐私或工作机密。具体危害大小，分两种情况：一种是泄露后能定位到你本人，直接“开盒”，另一种是无法溯源的泄露。

能定位本人的泄露情况最危险，这可能是因为你在疏忽大意的情况下勾选了某些选项，使原本私密的信息被设定为公开范围分享。字节旗下大模型“豆包”近日的风波便是一例。

正如视智未来此前报道提到的，起初，豆包被指使用大量AI聊天结果页面，污染搜索引擎结果。这种行为导致谷歌等搜索引擎，以及依赖它们的Perplexity等AI搜索产品，抓取的结果页面也是AI生成的，导致AI自我引用，结果质量螺旋式下降。然而，字节此举应该不是刻意污染互联网环境，他们可能只是没有意识到，对AI大模型使用同一招数时，事件的性质发生了改变。

豆包此举最大的问题在于，这些分享的页面来自真人用户与豆包的交互过程。用户分享某段豆包对话时，分享页面会自动勾选“将对话内容分享到整个网络”的选项，同时也没有7天/30天有效期、链接带密码等常见的选项。在不注意的前提下，可能会让你没有察觉到“我本来只想把这段共享给我的微信群而已”。

![Image](http://static.ylzbl.com/uploads/ueditor/php/upload/image/20240612/1718165133354962.jpeg)

当前，字节跳动已取消这种SEO尝试，并下架了据称多达2000多万条的AI对话页面。

可以定位到人的信息泄露还有其它情况。由于种种原因，我们可能需要与别人“拼车”使用ChatGPT、Midjourney等服务。使用这个账号的历史记录也是共享的，所以你可以看到别人的工作内容，并且通过这些记录与他本人对应起来。当一个共享账号中长时间出现某家公司的具体信息，我们自然可以认为，其中涉及的未发布产品或战略计划等信息很可能是真实的。

另一种泄露情况是不可定位到发布者本人的，主要是指输入的内容被用作训练大模型，并在某种情况下被吐出。但这种情形一般都伴随着严重的幻觉，所以几乎不可能100%匹配你当时输入的隐私内容。

在2023年ChatGPT刚刚兴起时，软银、日立等多家大型日企出台政策，禁止员工使用ChatGPT的公开服务。一些企业后来购买了企业版大模型服务，由官方承诺对机密内容的托管是安全的，甚至可以选择在公司内的服务器部署。至于最近非常火的“AI PC”，其本质也是使用高算力芯片，将一些原本需要联网的大模型运算改为本地生成，避免数据上传到远程服务器，而可能发生的泄漏情况。

以上两种情况是与AI能力相关的隐私泄露风险，但这些问题发生的概率很低，并且只要更改使用习惯，也很大程度上可以避免。

与这些相比，真正值得注意的隐私泄露风险，发生在其他地方。

多数大模型开发商在数据收集、存储和跨境传输等方面的安全保障能力有限。尽管国内的政策在大模型备案时，对其安全能力有基本要求，但客观上，小公司或初创团队的“技能树”多点在了研发方面，在安全运营方面确实可能有所欠缺。需要指出的是，这方面的隐私泄露风险是普遍存在的，并不是只有AI公司才有的。

让我们把视线转回到严肃批评苹果和OpenAI的马斯克身上。既然他对隐私如此看重，他自己的产业是否有过隐私泄露的历史呢？答案是肯定的。

特斯拉曾不止一次发生过用户数据泄露风波，不过较大的几次都是由于内部员工泄露所致。如今年5月发生的一起数据泄露事件，影响超过75000人，包括员工和客户记录。特斯拉调查发现这是两名前员工的“内部不法行为”所致,他们违反了特斯拉的IT安全和数据保护政策，泄露了这些信息。2019-2022年，至少9名特斯拉员工通过内部消息系统，私下分享了车载摄像头记录的音视频内容，包括一些车主的隐私视频和图像。

在国内造车“新势力”中，也有一些厂商曾收到职业黑客的敲诈勒索，或是公开了车主的信息数据库等。这是国内众多个人信息在暗网“倒卖”的案例之一。如果类似事情发生在AI工具中，那并不稀奇，但这些事故与AI技术的关系不大。

![Image](http://static.ylzbl.com/uploads/ueditor/php/upload/image/20240612/1718165134974775.jpeg)

作为普通的AIGC用户，我们要如何尽可能地保护自己，以避免隐私泄露的意外发生？

首先，按照苹果官方的介绍，当你在使用iOS/macOS的AI相关服务时，这些过程很难向OpenAI等第三方泄露隐私。如果你之前信任苹果的iCloud等服务，也可以继续放心使用“果工智能”。

对于其他AI服务，在使用过程中，应尽量避免输入个人和私密信息。即使使用Character.AI或类似的陪伴服务，它们必须通过读取你的个人隐私来变得更懂你、更贴心，你也需要保持警惕。

在拼车使用ChatGPT等账号时，如果是为公司工作，最好在输入过程中隐藏具体公司信息，可以使用一键替换的方式，并且在获得生成结果后，立即删除这段对话。可以通过将真实事件以“我有一个朋友”的方式转述，使用化名或代号替代真实公司、产品和地域信息，尽量避免将真实信息告诉在线大模型。

在使用诸如AI Pin、Rabbit R1或Meta-雷朋太阳镜等AI硬件时，它们希望你的输入是多模态的，例如对着摄像头问“这朵花是什么”。这种情况下，AI硬件可能要求24小时授权摄像头和麦克风的访问。这本身存在较高的隐私泄露风险，因此需要权衡安全性和便利性的利弊。

总体而言，使用AI服务就算不幸发生了隐私泄露，在目前，这也跟AI没有特别的关系，而是任何一家互联网公司都面临的同样的风险。了解这一点，可能会让你更放心地继续使用大模型等AI产品。

